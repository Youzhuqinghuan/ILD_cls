# ILD Segmentation Module - MedSAM2 Fine-tuning Pipeline

This module implements the **ILD (Interstitial Lung Disease) segmentation system** based on MedSAM2, specifically designed for 4-class lesion segmentation in HRCT images. The pipeline converts raw NIfTI medical images through complete preprocessing, training, inference, and evaluation workflows.

## æ ¸å¿ƒæ¶æ„æ¦‚è¿°

### å®Œæ•´è®­ç»ƒå·¥ä½œæµç¨‹
```
Raw Data (NIfTI) â†’ Preprocessing â†’ Training â†’ Inference â†’ Evaluation
     â†“                   â†“            â†“          â†“            â†“
[åŸå§‹CTå›¾åƒ]          [æ•°æ®æ ¼å¼è½¬æ¢]    [å¾®è°ƒSAM2]   [3Dåˆ†å‰²æ¨ç†]   [Diceè¯„ä¼°]
  â”œâ”€ CT_*.nii.gz       â”œâ”€ niiâ†’npz      â”œâ”€ å†»ç»“æç¤ºç¼–ç å™¨  â”œâ”€ slice-by-slice  â”œâ”€ å¤šç±»åˆ«DSC
  â””â”€ Labels_*.nii.gz   â””â”€ npzâ†’npy      â””â”€ è®­ç»ƒå›¾åƒç¼–ç å™¨  â””â”€ 3Dä½“ç§¯é‡å»º      â””â”€ å¯è§†åŒ–ç»“æœ
```

## è®­ç»ƒå…¥å£ï¼štrain.sh è„šæœ¬åˆ†æ

### æ‰§è¡Œæµç¨‹æ¦‚è§ˆ
`train.sh` æ˜¯æ•´ä¸ªè®­ç»ƒç³»ç»Ÿçš„ç»Ÿä¸€å…¥å£ï¼Œé›†æˆäº†æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€æ¨ç†å’Œè¯„ä¼°å››ä¸ªé˜¶æ®µï¼š

```bash
# æ ¸å¿ƒæ‰§è¡Œé˜¶æ®µ
1. æ•°æ®é¢„å¤„ç† (nii_to_npz.py)    # NIfTI â†’ NPZ æ ¼å¼è½¬æ¢
2. è®­ç»ƒæ•°æ®å‡†å¤‡ (npz_to_npy.py)   # NPZ â†’ NPY æ ¼å¼è½¬æ¢  
3. æ¨¡å‹è®­ç»ƒ (finetune_sam2_img.py) # SAM2å¾®è°ƒè®­ç»ƒ
4. æ¨ç†è¯„ä¼° (infer_medsam2_ILD.py + compute_metrics_ILD_all.py)
```

### å…³é”®é…ç½®å‚æ•°
```bash
# æ•°æ®è·¯å¾„é…ç½®
IMG_PATH="/home/huchengpeng/ILD/imagesTr"          # CTå›¾åƒè·¯å¾„
GT_PATH="/home/huchengpeng/ILD/labelsTr"           # æ ‡ç­¾è·¯å¾„
IMG_NAME_SUFFIX="_0000.nii.gz"                     # CTæ–‡ä»¶åç¼€
GT_NAME_SUFFIX=".nii.gz"                           # æ ‡ç­¾æ–‡ä»¶åç¼€

# é¢„å¤„ç†å‚æ•° (CTçª—å®½çª—ä½è®¾ç½®)
WINDOW_LEVEL=40                                     # è½¯ç»„ç»‡çª—ä½
WINDOW_WIDTH=400                                    # è½¯ç»„ç»‡çª—å®½

# è®­ç»ƒè¶…å‚æ•°
EPOCHS=500                                          # è®­ç»ƒè½®æ•°
BATCH_SIZE=16                                       # æ‰¹å¤„ç†å¤§å°
L_RATE=1e-5                                        # å­¦ä¹ ç‡
MODEL_CFG="sam2_hiera_t.yaml"                      # æ¨¡å‹é…ç½®(Tinyç‰ˆæœ¬)
```

## æ•°æ®é¢„å¤„ç†ç®¡é“è¯¦ç»†åˆ†æ

### æ•°æ®æµæ¦‚è§ˆï¼šä»æ‚£è€…çº§åˆ«åˆ°åˆ‡ç‰‡çº§åˆ«

```
æ‚£è€…çº§åˆ« CT æ–‡ä»¶ â†’ ROI æå– â†’ åˆ‡ç‰‡åˆ†è§£ â†’ è®­ç»ƒ/æ¨ç†
       â†“              â†“           â†“           â†“
[3D NIfTI å…¨ä½“ç§¯]  [NPZ æœ‰æ•ˆåˆ‡ç‰‡]  [NPY å•åˆ‡ç‰‡]  [è¾¹ç•Œæ¡†æŒ‡å¯¼]
  â”œâ”€ CT_NSIP1_0000.nii.gz  â”œâ”€ ä»…ç—…ç¶åˆ‡ç‰‡    â”œâ”€ å•ç‹¬ä¿å­˜     â”œâ”€ è®­ç»ƒæ—¶ï¼šGTè®¡ç®—
  â”œâ”€ (512, 512, 200)       â”œâ”€ ç©ºé—´å‹ç¼©     â”œâ”€ 256Ã—256      â”œâ”€ æ¨ç†æ—¶ï¼šä¼ æ’­è®¡ç®—
  â””â”€ å®Œæ•´èƒ¸éƒ¨æ‰«æ           â””â”€ ROIæå–      â””â”€ 3é€šé“æ ¼å¼     â””â”€ 3Dè¿ç»­æ€§ä¿æŒ
```

### é˜¶æ®µ1: NIfTI â†’ NPZ è½¬æ¢ (nii_to_npz.py)

#### æ ¸å¿ƒåŠŸèƒ½ï¼šæ‚£è€…çº§åˆ«æ•°æ®è¯»å–ä¸ROIæå–
- **è¾“å…¥**: åŸå§‹CTå›¾åƒ (`CT_*_0000.nii.gz`) å’Œå¯¹åº”æ ‡ç­¾ (`CT_*.nii.gz`)
- **è¾“å‡º**: é¢„å¤„ç†åçš„NPZå‹ç¼©æ–‡ä»¶ï¼ŒåŒ…å«å›¾åƒã€æ ‡ç­¾å’Œç©ºé—´ä¿¡æ¯
- **å¤„ç†çº§åˆ«**: ä»¥æ‚£è€…ä¸ºå•ä½ï¼Œå¤„ç†å®Œæ•´3Dä½“ç§¯

#### è¯¦ç»†æ•°æ®è¯»å–æµç¨‹

1. **æ‚£è€…æ–‡ä»¶é…å¯¹è¯»å–**
```python
def preprocess(name, npz_path):
    # é€šè¿‡æ–‡ä»¶åè‡ªåŠ¨é…å¯¹CTå›¾åƒå’Œæ ‡ç­¾
    image_name = name.split(gt_name_suffix)[0] + img_name_suffix
    # ä¾‹ï¼šCT_NSIP1.nii.gz â†’ CT_NSIP1_0000.nii.gz
    
    # å…ˆè¯»å–æ ‡ç­¾ç¡®å®šROIä½ç½®
    gt_sitk = sitk.ReadImage(join(gt_path, gt_name))
    gt_data_ori = np.uint8(sitk.GetArrayFromImage(gt_sitk))  # Shape: (Z, H, W)
    
    # å†è¯»å–å¯¹åº”çš„CTå›¾åƒ
    img_sitk = sitk.ReadImage(join(nii_path, image_name))
    image_data = sitk.GetArrayFromImage(img_sitk)  # Shape: (Z, H, W)
```

2. **æ™ºèƒ½ROIå±‚é¢é€‰æ‹©ç­–ç•¥**
```python
# æ­¥éª¤1: 3Då°ç›®æ ‡è¿‡æ»¤ (å»é™¤<1000åƒç´ çš„3Dè¿é€šåŸŸ)
gt_data_ori = cc3d.dust(gt_data_ori, threshold=1000, connectivity=26)

# æ­¥éª¤2: 2Då°ç›®æ ‡è¿‡æ»¤ (æ¯ä¸ªåˆ‡ç‰‡å»é™¤<100åƒç´ çš„åŒºåŸŸ)
for slice_i in range(gt_data_ori.shape[0]):
    gt_i = gt_data_ori[slice_i, :, :]
    gt_data_ori[slice_i, :, :] = cc3d.dust(gt_i, threshold=100, connectivity=8)

# æ­¥éª¤3: è¯†åˆ«æ‰€æœ‰åŒ…å«ç—…ç¶çš„Zè½´åˆ‡ç‰‡
z_index, _, _ = np.where(gt_data_ori > 0)
z_index = np.unique(z_index)

# æ­¥éª¤4: ä»…æå–æœ‰æ•ˆROIåˆ‡ç‰‡ (å¤§å¹…å‡å°‘å­˜å‚¨ç©ºé—´)
if len(z_index) > 0:
    gt_roi = gt_data_ori[z_index, :, :]      # ä»…ç—…ç¶åˆ‡ç‰‡
    img_roi = image_data_pre[z_index, :, :]  # å¯¹åº”CTåˆ‡ç‰‡
    
# ç»“æœï¼šä»~200å±‚å‡å°‘åˆ°~20-50å±‚æœ‰æ•ˆåˆ‡ç‰‡
```

3. **ROIé€‰æ‹©çš„å…³é”®ä¼˜åŠ¿**
- **å­˜å‚¨ä¼˜åŒ–**: å¹³å‡å‡å°‘60-80%çš„å­˜å‚¨ç©ºé—´
- **è®¡ç®—æ•ˆç‡**: è®­ç»ƒæ—¶æ— éœ€å¤„ç†ç©ºç™½åˆ‡ç‰‡  
- **è´¨é‡æå‡**: å°ç›®æ ‡è¿‡æ»¤å»é™¤æ ‡æ³¨å™ªå£°
- **ä¸Šä¸‹æ–‡ä¿æŒ**: ä¿ç•™ç—…ç¶å‘¨å›´çš„ç©ºé—´ä¿¡æ¯

4. **CTå›¾åƒçª—å®½çª—ä½æ ‡å‡†åŒ–**
```python
# è½¯ç»„ç»‡çª—è®¾ç½® (Window Level=40, Window Width=400)
lower_bound = WINDOW_LEVEL - WINDOW_WIDTH / 2  # -160 HU
upper_bound = WINDOW_LEVEL + WINDOW_WIDTH / 2  # 240 HU
image_data_pre = np.clip(image_data, lower_bound, upper_bound)

# å½’ä¸€åŒ–åˆ° [0, 255] ç¡®ä¿ä¸€è‡´çš„å¯¹æ¯”åº¦
image_data_pre = ((image_data_pre - np.min(image_data_pre)) / 
                  (np.max(image_data_pre) - np.min(image_data_pre)) * 255.0)
image_data_pre = np.uint8(image_data_pre)
```

### é˜¶æ®µ2: NPZ â†’ NPY è½¬æ¢ (npz_to_npy.py)

#### æ ¸å¿ƒåŠŸèƒ½ï¼šåˆ‡ç‰‡çº§åˆ«æ•°æ®å‡†å¤‡
å°†NPZæ ¼å¼è½¬æ¢ä¸ºè®­ç»ƒå‹å¥½çš„NPYæ ¼å¼ï¼Œå®ç°ä»æ‚£è€…çº§åˆ«åˆ°åˆ‡ç‰‡çº§åˆ«çš„è½¬æ¢

#### æ•°æ®å•ä½è½¬æ¢ç­–ç•¥

1. **3Dæ‚£è€… â†’ 2Dåˆ‡ç‰‡åˆ†è§£**
```python
def convert_npz_to_npy(npz_name, npz_dir, npy_dir):
    npz = np.load(npz_path, allow_pickle=True, mmap_mode="r")
    imgs = npz["imgs"]  # Shape: (N_slices, H, W) - æ‚£è€…çš„æœ‰æ•ˆåˆ‡ç‰‡
    gts = npz["gts"]    # Shape: (N_slices, H, W) - å¯¹åº”æ ‡ç­¾
    
    # é€sliceåˆ†è§£å¹¶ç‹¬ç«‹ä¿å­˜
    for i in range(imgs.shape[0]):
        img_i = imgs[i, :, :]  # å•ä¸ªåˆ‡ç‰‡
        gt_i = gts[i, :, :]    # å•ä¸ªæ ‡ç­¾
        
        # åˆ‡ç‰‡æ–‡ä»¶å‘½å: æ‚£è€…å-åˆ‡ç‰‡ç´¢å¼•
        slice_name = name + "-" + str(i).zfill(3)  # ä¾‹: CT_NSIP1-001.npy
        np.save(join(npy_dir, "imgs", slice_name + ".npy"), img_3c)
        np.save(join(npy_dir, "gts", slice_name + ".npy"), gt_i)
```

2. **è®­ç»ƒä¼˜åŒ–çš„æ ¼å¼æ ‡å‡†åŒ–**
```python
# å›¾åƒæ ¼å¼é€‚é…SAM2è¾“å…¥è¦æ±‚
img_3c = np.repeat(img_i[:, :, None], 3, axis=-1)  # ç°åº¦â†’RGB 3é€šé“

# æ ‡ç­¾åˆ†è¾¨ç‡ä¼˜åŒ– (æé«˜è®­ç»ƒæ•ˆç‡)  
gt_i = cv2.resize(gt_i, (256, 256), interpolation=cv2.INTER_NEAREST)
# åŸå§‹: (512, 512) â†’ è®­ç»ƒ: (256, 256)ï¼Œæ¨ç†æ—¶å†upscaleåˆ°1024
```

#### æ•°æ®å•ä½å¯¹æ¯”æ€»ç»“

| é˜¶æ®µ | æ•°æ®å•ä½ | æ–‡ä»¶æ ¼å¼ | å…¸å‹å°ºå¯¸ | ç”¨é€” |
|------|----------|----------|----------|------|
| é¢„å¤„ç†è¾“å…¥ | æ‚£è€…çº§åˆ« | .nii.gz | (200, 512, 512) | å®Œæ•´CTæ‰«æ |
| NPZä¸­é—´æ ¼å¼ | æ‚£è€…çº§åˆ« | .npz | (50, 512, 512) | ROIæå–å |
| NPYè®­ç»ƒæ ¼å¼ | **åˆ‡ç‰‡çº§åˆ«** | .npy | (256, 256) | å•åˆ‡ç‰‡è®­ç»ƒ |
| æ¨ç†å¤„ç† | æ‚£è€…çº§åˆ«â†’åˆ‡ç‰‡çº§åˆ« | .npzâ†’é€slice | (1024, 1024) | é€sliceæ¨ç† |

## è®­ç»ƒä¸æ¨ç†çš„æ•°æ®å¤„ç†ç­–ç•¥

### è®­ç»ƒæ—¶ï¼šåˆ‡ç‰‡çº§åˆ«å¤„ç† + è¾¹ç•Œæ¡†è®¡ç®—

#### NpyDataset æ•°æ®åŠ è½½æœºåˆ¶
```python
class NpyDataset(Dataset):
    def __getitem__(self, index):
        # 1. åŠ è½½å•ä¸ªåˆ‡ç‰‡æ•°æ®
        img = np.load(img_path)    # Shape: (1024, 1024, 3) 
        gt = np.load(gt_path)      # Shape: (256, 256), å¤šç±»åˆ«æ ‡ç­¾
        
        # 2. éšæœºé€‰æ‹©å•ä¸ªç—…ç¶ç±»åˆ« (æ•°æ®å¹³è¡¡ç­–ç•¥)
        label_ids = np.unique(gt)[1:]  # æ’é™¤èƒŒæ™¯(0)
        selected_label = random.choice(label_ids.tolist())
        gt2D = np.uint8(gt == selected_label)  # è½¬ä¸ºäºŒå€¼mask
        
        # 3. åŸºäºGTæ ‡ç­¾è®¡ç®—ç´§è‡´è¾¹ç•Œæ¡†
        y_indices, x_indices = np.where(gt2D > 0)
        x_min, x_max = np.min(x_indices), np.max(x_indices) 
        y_min, y_max = np.min(y_indices), np.max(y_indices)
        
        # 4. è¾¹ç•Œæ¡†éšæœºæ‰°åŠ¨ (æ•°æ®å¢å¼º)
        x_min = max(0, x_min - random.randint(0, self.bbox_shift))  # bbox_shift=5
        x_max = min(W, x_max + random.randint(0, self.bbox_shift))
        y_min = max(0, y_min - random.randint(0, self.bbox_shift)) 
        y_max = min(H, y_max + random.randint(0, self.bbox_shift))
        
        # 5. åæ ‡å°ºåº¦é€‚é… (256 â†’ 1024)
        bboxes = np.array([x_min, y_min, x_max, y_max]) * 4
        
        return img_1024, gt2D, bboxes, img_name
```

#### è®­ç»ƒæ—¶è¾¹ç•Œæ¡†ç¡®å®šåŸç†
- **æ•°æ®æ¥æº**: ç›´æ¥ä»Ground Truthæ ‡ç­¾è®¡ç®—
- **è®¡ç®—æ–¹æ³•**: æœ€å°å¤–æ¥çŸ©å½¢ + éšæœºæ‰°åŠ¨  
- **æ‰°åŠ¨èŒƒå›´**: Â±5åƒç´  (æé«˜æ¨¡å‹é²æ£’æ€§)
- **å°ºåº¦è½¬æ¢**: æ ‡ç­¾256Ã—256 â†’ æ¨¡å‹è¾“å…¥1024Ã—1024

### æ¨ç†æ—¶ï¼šæ‚£è€…çº§åˆ«å¤„ç† + 3Dè¾¹ç•Œæ¡†ä¼ æ’­

#### æ¨ç†æ•°æ®å•ä½ä¸è¾¹ç•Œæ¡†ç­–ç•¥
```python
def main(name):  # name: æ‚£è€…çº§åˆ«NPZæ–‡ä»¶
    npz = np.load(npz_path)
    img_3D = npz['imgs']   # æ‚£è€…å®Œæ•´æœ‰æ•ˆåˆ‡ç‰‡ (N, H, W)
    gt_3D = npz['gts']     # ç”¨äºç¡®å®šåˆå§‹è¾¹ç•Œæ¡† (æµ‹è¯•æ—¶æœ‰GT)
    
    # å¯¹æ¯ä¸ªç—…ç¶ç±»åˆ«åˆ†åˆ«è¿›è¡Œ3Dåˆ†å‰²
    for label_id in label_ids:
        # 1. åˆå§‹è¾¹ç•Œæ¡†è®¡ç®—ï¼šæ‰¾æœ€å¤§ç—…ç¶åˆ‡ç‰‡
        for z in marker_zids:  # åŒ…å«è¯¥ç±»åˆ«ç—…ç¶çš„æ‰€æœ‰åˆ‡ç‰‡
            z_box = get_bbox(marker_data_id[z, :, :])  # æ¯å±‚çš„è¾¹ç•Œæ¡†
            bbox_dict[z] = z_box
        
        # 2. ç¡®å®šèµ·å§‹åˆ‡ç‰‡ï¼šé€‰æ‹©ç—…ç¶é¢ç§¯æœ€å¤§çš„åˆ‡ç‰‡
        bbox_areas = [np.prod(bbox_dict[z][2:] - bbox_dict[z][:2]) for z in bbox_dict.keys()]
        z_max_area = list(bbox_dict.keys())[np.argmax(bbox_areas)]
        z_middle = int((z_max - z_min)/2 + z_min)
        
        # 3. åŒå‘ä¼ æ’­æ¨ç†ç­–ç•¥
        # å‘ä¸Šæ¨ç† (z_middle â†’ z_max)
        for z in range(z_middle, z_max):
            if z == z_middle:
                # èµ·å§‹åˆ‡ç‰‡ï¼šä½¿ç”¨æœ€å¤§ç—…ç¶çš„è¾¹ç•Œæ¡†
                box_1024 = mid_slice_bbox_2d / np.array([W, H, W, H]) * 1024
            else:
                # åç»­åˆ‡ç‰‡ï¼šåŸºäºå‰ä¸€åˆ‡ç‰‡çš„åˆ†å‰²ç»“æœè®¡ç®—è¾¹ç•Œæ¡†  
                pre_seg = segs_3d_temp[z-1, :, :]
                if np.max(pre_seg) > 0:
                    box_1024 = get_bbox(pre_seg)  # ä¼ æ’­è¾¹ç•Œæ¡†
                else:
                    box_1024 = mid_slice_bbox_2d / np.array([W, H, W, H]) * 1024  # å›é€€ç­–ç•¥
            
            # å•åˆ‡ç‰‡æ¨ç†
            img_2d_seg = medsam_inference(medsam_model, features, box_1024, H, W)
            segs_3d_temp[z, img_2d_seg>0] = 1
        
        # å‘ä¸‹æ¨ç† (z_middle-1 â†’ z_min) - åŒæ ·çš„ä¼ æ’­ç­–ç•¥
```

#### æ¨ç†æ—¶è¾¹ç•Œæ¡†ç¡®å®šçš„3Dç­–ç•¥

1. **åˆå§‹å®šä½**: 
   - åˆ†ææ¯ä¸ªåˆ‡ç‰‡çš„ç—…ç¶åˆ†å¸ƒ
   - é€‰æ‹©ç—…ç¶é¢ç§¯æœ€å¤§çš„åˆ‡ç‰‡ä½œä¸ºèµ·å§‹ç‚¹
   - ç¡®ä¿ä»æœ€å¯é çš„ä½ç½®å¼€å§‹æ¨ç†

2. **3Dä¼ æ’­æœºåˆ¶**:
   - **å‰å‘ä¼ æ’­**: ä½¿ç”¨å‰ä¸€åˆ‡ç‰‡çš„åˆ†å‰²ç»“æœæŒ‡å¯¼å½“å‰åˆ‡ç‰‡
   - **è‡ªé€‚åº”è°ƒæ•´**: è‹¥å‰ä¸€åˆ‡ç‰‡æ— åˆ†å‰²ç»“æœï¼Œå›é€€åˆ°åˆå§‹è¾¹ç•Œæ¡†
   - **è¿ç»­æ€§ä¿æŒ**: ç¡®ä¿3Dä½“ç§¯çš„ç©ºé—´è¿ç»­æ€§

3. **è¾¹ç•Œæ¡†ä¼ æ’­ä¼˜åŠ¿**:
   - **ä¸Šä¸‹æ–‡åˆ©ç”¨**: å……åˆ†åˆ©ç”¨3Dç©ºé—´ä¿¡æ¯
   - **è¯¯å·®çº æ­£**: å•åˆ‡ç‰‡é”™è¯¯ä¸ä¼šæ— é™ä¼ æ’­  
   - **æ•ˆç‡æå‡**: é¿å…å…¨å›¾æœç´¢ï¼Œèšç„¦ROIåŒºåŸŸ

### æ•°æ®å¤„ç†æµç¨‹æ€»ç»“

#### å®Œæ•´æ•°æ®æµå¯¹æ¯”

| å¤„ç†é˜¶æ®µ | è¾“å…¥æ•°æ® | è¾“å‡ºæ•°æ® | æ•°æ®å•ä½ | è¾¹ç•Œæ¡†æ¥æº | ä¸»è¦ç›®çš„ |
|----------|----------|----------|----------|------------|----------|
| **é¢„å¤„ç†** | NIfTIå®Œæ•´CT | NPZ ROIåˆ‡ç‰‡ | æ‚£è€…çº§åˆ« | - | å­˜å‚¨ä¼˜åŒ–+è´¨é‡æå‡ |
| **è®­ç»ƒå‡†å¤‡** | NPZæ‚£è€…æ•°æ® | NPYå•åˆ‡ç‰‡ | åˆ‡ç‰‡çº§åˆ« | GTæ ‡ç­¾è®¡ç®— | è®­ç»ƒæ•°æ®å‡†å¤‡ |
| **æ¨¡å‹è®­ç»ƒ** | NPYå•åˆ‡ç‰‡ | åˆ†å‰²é¢„æµ‹ | åˆ‡ç‰‡çº§åˆ« | GT+éšæœºæ‰°åŠ¨ | æ¨¡å‹å­¦ä¹  |
| **æ¨¡å‹æ¨ç†** | NPZæ‚£è€…æ•°æ® | 3Dåˆ†å‰²ç»“æœ | æ‚£è€…â†’åˆ‡ç‰‡ | 3Dä¼ æ’­ç­–ç•¥ | ä¸´åºŠåº”ç”¨ |

#### å…³é”®æŠ€æœ¯åˆ›æ–°

1. **è‡ªé€‚åº”ROIæå–**: åŸºäºç—…ç¶åˆ†å¸ƒæ™ºèƒ½é€‰æ‹©æœ‰æ•ˆåˆ‡ç‰‡
2. **å¤šå°ºåº¦æ•°æ®æµ**: é¢„å¤„ç†(512)â†’è®­ç»ƒ(256)â†’æ¨ç†(1024)çš„çµæ´»å°ºåº¦è½¬æ¢  
3. **3D-2DååŒ**: ä¿æŒ3Dä¸Šä¸‹æ–‡çš„é€åˆ‡ç‰‡å¤„ç†ç­–ç•¥
4. **æ™ºèƒ½è¾¹ç•Œæ¡†ä¼ æ’­**: ä»å¯é èµ·ç‚¹å¼€å§‹çš„åŒå‘3Dä¼ æ’­æœºåˆ¶

## æ¨¡å‹è®­ç»ƒè¯¦ç»†å®ç° (finetune_sam2_img.py)

### SAM2æ¶æ„é€‚é…

#### MedSAM2æ¨¡å‹å®šä¹‰
```python
class MedSAM2(nn.Module):
    def __init__(self, model):
        super().__init__()
        self.sam2_model = model
        # ğŸ”’ å†»ç»“æç¤ºç¼–ç å™¨ (ä¸“æ³¨äºå›¾åƒç†è§£)
        for param in self.sam2_model.sam_prompt_encoder.parameters():
            param.requires_grad = False
```

#### å¯è®­ç»ƒå‚æ•°ç»Ÿè®¡
```python
# ä»…è®­ç»ƒå›¾åƒç¼–ç å™¨ + æ©è†œè§£ç å™¨
img_mask_encdec_params = (
    list(medsam_model.sam2_model.image_encoder.parameters()) + 
    list(medsam_model.sam2_model.sam_mask_decoder.parameters())
)
```

### æ•°æ®å¢å¼ºç­–ç•¥

#### NpyDatasetç±»å®ç°
```python
class NpyDataset(Dataset):
    def __getitem__(self, index):
        # éšæœºé€‰æ‹©ç—…ç¶ç±»åˆ« (æ•°æ®å¹³è¡¡)
        label_ids = np.unique(gt)[1:]  # æ’é™¤èƒŒæ™¯
        gt2D = np.uint8(gt == random.choice(label_ids.tolist()))
        
        # è¾¹ç•Œæ¡†æ‰°åŠ¨ (æé«˜é²æ£’æ€§)
        x_min = max(0, x_min - random.randint(0, self.bbox_shift))
        x_max = min(W, x_max + random.randint(0, self.bbox_shift))
        
        # åæ ‡ç¼©æ”¾ 256â†’1024
        bboxes = np.array([x_min, y_min, x_max, y_max]) * 4
```

### è®­ç»ƒå¾ªç¯æ ¸å¿ƒé€»è¾‘

#### æŸå¤±å‡½æ•°ç»„åˆ
```python
# Dice Loss + äº¤å‰ç†µ (å¤„ç†ç±»åˆ«ä¸å¹³è¡¡)
seg_loss = monai.losses.DiceLoss(sigmoid=True, squared_pred=True, reduction="mean")
ce_loss = nn.BCEWithLogitsLoss(reduction="mean")
total_loss = seg_loss(medsam_pred, gt2D) + ce_loss(medsam_pred, gt2D.float())
```

#### æ¨¡å‹ä¿å­˜ç­–ç•¥
```python
# å®æ—¶ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
torch.save(checkpoint, join(model_save_path, "medsam_model_latest.pth"))
# åŸºäºéªŒè¯æŸå¤±ä¿å­˜æœ€ä½³æ¨¡å‹
if val_loss < best_loss:
    torch.save(checkpoint, join(model_save_path, "medsam_model_best.pth"))
```

## æ¨ç†ç³»ç»Ÿå®ç° (infer_medsam2_ILD.py)

### 3Dæ¨ç†ç­–ç•¥

#### æ ‡ç­¾æ˜ å°„å®šä¹‰
```python
label_dict = {
    1: 'ILD1',           # æœªçŸ¥ç±»å‹1
    2: 'Reticulation',   # ç½‘çŠ¶å½±  
    3: 'GGO-reticulation', # ç£¨ç»ç’ƒ-ç½‘çŠ¶æ··åˆå½±
    4: 'ILD4',           # æœªçŸ¥ç±»å‹4
    5: 'Honeycombing',   # èœ‚çªçŠ¶
}
```

#### Slice-by-Slice æ¨ç†æµç¨‹
1. **ä¸­å¿ƒåˆ‡ç‰‡å®šä½**: æ‰¾åˆ°ç—…ç¶æœ€å¤§çš„åˆ‡ç‰‡ä½œä¸ºèµ·å§‹ç‚¹
2. **åŒå‘ä¼ æ’­**: ä»ä¸­å¿ƒå‘ä¸¤ç«¯è¿›è¡Œåºåˆ—æ¨ç†
3. **è¾¹ç•Œæ¡†ä¼ æ’­**: ä½¿ç”¨å‰ä¸€åˆ‡ç‰‡çš„ç»“æœæŒ‡å¯¼å½“å‰åˆ‡ç‰‡çš„è¾¹ç•Œæ¡†

```python
def main(name):
    # å¯¹æ¯ä¸ªç—…ç¶ç±»åˆ«å•ç‹¬å¤„ç†
    for label_id in label_ids:
        # æ‰¾åˆ°ç—…ç¶æœ€å¤§çš„åˆ‡ç‰‡
        z_max_area = list(bbox_dict.keys())[np.argmax(bbox_areas)]
        z_middle = int((z_max - z_min)/2 + z_min)
        
        # å‘ä¸Šæ¨ç† (z_middle â†’ z_max)
        for z in range(z_middle, z_max):
            if z == z_middle:
                box_1024 = mid_slice_bbox_2d / np.array([W, H, W, H]) * 1024
            else:
                # ä½¿ç”¨å‰ä¸€åˆ‡ç‰‡çš„åˆ†å‰²ç»“æœæŒ‡å¯¼è¾¹ç•Œæ¡†
                pre_seg = segs_3d_temp[z-1, :, :]
                box_1024 = get_bbox(pre_seg1024)
        
        # å‘ä¸‹æ¨ç† (z_middle-1 â†’ z_min)  
        for z in range(z_middle-1, z_min, -1):
            pre_seg = segs_3d_temp[z+1, :, :]
            box_1024 = get_bbox(pre_seg1024)
```

## è¯„ä¼°ç³»ç»Ÿå®ç° (compute_metrics_ILD_all.py)

### å¤šç±»åˆ«Diceè¯„ä¼°

#### æ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡
```python
def compute_dice_coefficient(mask_gt, mask_pred):
    """è®¡ç®—Soerensen-Diceç³»æ•°"""
    intersection = np.sum(mask_gt * mask_pred)
    return 2 * intersection / (np.sum(mask_gt) + np.sum(mask_pred))

def compute_multi_class_dsc(gt_data, pred_data):
    """è®¡ç®—å¤šç±»åˆ«DSC"""
    for i in label_dict.keys():
        gt_i = (gt_data == i).astype(np.uint8)
        pred_i = (pred_data == i).astype(np.uint8)
        
        if np.sum(gt_i) == 0 and np.sum(pred_i) == 0:
            dsc[label_dict[i]] = np.nan  # éƒ½ä¸ºç©ºæ—¶è¿”å›NaN
        elif np.sum(gt_i) == 0 and np.sum(pred_i) > 0:
            dsc[label_dict[i]] = 0       # GTä¸ºç©ºä½†é¢„æµ‹éç©ºæ—¶è¿”å›0
        else:
            dsc[label_dict[i]] = compute_dice_coefficient(gt_i, pred_i)
```

#### è¯„ä¼°è¾“å‡º
1. **å¹³å‡DSCè®¡ç®—**: å¯¹æ¯ä¸ªç±»åˆ«è®¡ç®—æ‰€æœ‰æœ‰æ•ˆåˆ‡ç‰‡çš„å¹³å‡Diceç³»æ•°
2. **CSVç»“æœä¿å­˜**: ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š
3. **å¯è§†åŒ–å›¾è¡¨**: ä¸ºæ¯ä¸ªç±»åˆ«ç”ŸæˆDSCåˆ†å¸ƒæŸ±çŠ¶å›¾

## ILDç‰¹å®šçš„4ç±»åˆ†å‰²æ ‡ç­¾

æœ¬ç³»ç»Ÿä¸“é—¨é’ˆå¯¹ILDçš„4ç±»ç—…ç¶è¿›è¡Œåˆ†å‰²ï¼š

| æ ‡ç­¾ID | ç—…ç¶ç±»å‹ | ä¸´åºŠæ„ä¹‰ |
|--------|----------|----------|
| 1 | ILD1 | å¾…åˆ†ç±»é—´è´¨ç—…å˜ |
| 2 | Reticulation | ç½‘çŠ¶å½± (çº¤ç»´åŒ–æ ‡å¿—) |
| 3 | GGO-reticulation | æ··åˆå‹ç—…å˜ |
| 4 | ILD4 | å¾…åˆ†ç±»é—´è´¨ç—…å˜ |
| 5 | Honeycombing | èœ‚çªçŠ¶ (ç»ˆæœ«æœŸçº¤ç»´åŒ–) |

## æŠ€æœ¯ç‰¹ç‚¹ä¸åˆ›æ–°

### 1. åŒ»å­¦å›¾åƒé€‚é…ä¼˜åŒ–
- **çª—å®½çª—ä½æ ‡å‡†åŒ–**: é‡‡ç”¨è½¯ç»„ç»‡çª— (40/400) ç¡®ä¿ä¸€è‡´çš„å¯¹æ¯”åº¦
- **3Dä¸Šä¸‹æ–‡åˆ©ç”¨**: é€šè¿‡sliceä¼ æ’­ä¿æŒ3Dè¿ç»­æ€§
- **å°ç›®æ ‡è¿‡æ»¤**: å»é™¤å™ªå£°æ ‡æ³¨æé«˜åˆ†å‰²è´¨é‡

### 2. è®­ç»ƒç­–ç•¥ä¼˜åŒ–  
- **é€‰æ‹©æ€§å¾®è°ƒ**: ä»…è®­ç»ƒå›¾åƒç¼–ç å™¨å’Œæ©è†œè§£ç å™¨
- **æ•°æ®å¢å¼º**: è¾¹ç•Œæ¡†æ‰°åŠ¨ + éšæœºç±»åˆ«é€‰æ‹©
- **æŸå¤±å‡½æ•°**: Dice+CEç»„åˆå¤„ç†ç±»åˆ«ä¸å¹³è¡¡

### 3. æ¨ç†æ•ˆç‡ä¼˜åŒ–
- **ä¸­å¿ƒå¯åŠ¨ç­–ç•¥**: ä»æœ€å¤§ç—…ç¶åˆ‡ç‰‡å¼€å§‹æ¨ç†
- **è‡ªé€‚åº”è¾¹ç•Œæ¡†**: åŸºäºå‰ä¸€åˆ‡ç‰‡ç»“æœæŒ‡å¯¼å½“å‰æ¨ç†
- **å¤šè¿›ç¨‹å¹¶è¡Œ**: æ”¯æŒå¤šworkerå¹¶è¡Œæ¨ç†

## å†…å­˜ä¸è®¡ç®—è¦æ±‚

- **è®­ç»ƒè¦æ±‚**: ~42GB GPUå†…å­˜ (A6000, batch_size=16)
- **æ¨ç†è¦æ±‚**: ~8GB GPUå†…å­˜ 
- **é¢„å¤„ç†**: æ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œ (å¯é…ç½®workeræ•°é‡)
- **å­˜å‚¨éœ€æ±‚**: NPZæ ¼å¼æ¯”åŸå§‹NIfTIå‡å°‘~60%å­˜å‚¨ç©ºé—´

## å®‰è£…ä¸ç¯å¢ƒé…ç½®

### ç¯å¢ƒè¦æ±‚
- `Ubuntu 20.04` | Python `3.10` | `CUDA 12.1+` | `PyTorch 2.3.1`

### å®‰è£…æ­¥éª¤
```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n sam2_in_med python=3.10 -y
conda activate sam2_in_med

# 2. å®‰è£…PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 3. å…‹éš†MedSAM2ä»“åº“
git clone -b MedSAM2 https://github.com/bowang-lab/MedSAM/

# 4. è®¾ç½®CUDAç¯å¢ƒ
export CUDA_HOME=/usr/local/cuda-12.1

# 5. å®‰è£…MedSAM2
cd MedSAM2 && pip install -e .

# 6. å®‰è£…ä¾èµ–åŒ…
pip install SimpleITK nibabel scikit-image connected-components-3d
pip install monai matplotlib pandas tqdm
```

### æ¨¡å‹æƒé‡ä¸‹è½½
```bash
# ä¸‹è½½SAM2é¢„è®­ç»ƒæƒé‡
mkdir checkpoints
wget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt -O checkpoints/sam2_hiera_tiny.pt
```

## ä½¿ç”¨æŒ‡å—

### å®Œæ•´è®­ç»ƒæµç¨‹
```bash
# 1. é…ç½®train.shä¸­çš„æ•°æ®è·¯å¾„
# 2. è®¾ç½®è®­ç»ƒ/æ¨ç†æ¨¡å¼
TRAINORINFER=1  # è®­ç»ƒæ¨¡å¼

# 3. æ‰§è¡Œå®Œæ•´pipeline
bash train.sh
```

### ä»…æ¨ç†æ¨¡å¼
```bash
# è®¾ç½®æ¨ç†æ¨¡å¼
TRAINORINFER=2  # æ¨ç†æ¨¡å¼
USEMEDSAM=true  # ä½¿ç”¨å¾®è°ƒåçš„MedSAM2

# æ‰§è¡Œæ¨ç†
bash train.sh
```

### å•ç‹¬æ‰§è¡Œå„é˜¶æ®µ
```bash
# æ•°æ®é¢„å¤„ç†
python nii_to_npz.py -img_path /path/to/images -gt_path /path/to/labels -output_path ./data/ILD

# æ ¼å¼è½¬æ¢
python npz_to_npy.py -npz_train_dir ./data/ILD/npz_train/CT_ILD -npy_dir ./data/ILD/npy

# æ¨¡å‹è®­ç»ƒ
python finetune_sam2_img.py -i ./data/ILD/npy -task_name MedSAM2-Tiny-ILD

# æ¨ç†è¯„ä¼°
python infer_medsam2_ILD.py -data_root ./data/ILD/npz_test/CT_ILD -pred_save_dir ./segs/medsam2
python ./metrics/compute_metrics_ILD_all.py -s ./segs/medsam2 -g /path/to/ground_truth
```

## è‡´è°¢

- æ„Ÿè°¢Meta AIå¼€æºSAM2æ¨¡å‹
- æ„Ÿè°¢MedSAMå›¢é˜Ÿæä¾›åŒ»å­¦å›¾åƒåˆ†å‰²åŸºç¡€æ¡†æ¶
- åŸºäºMedSAM2è®ºæ–‡: [Segment Anything in Medical Images and Videos](https://arxiv.org/abs/2408.03322)

---

**æœ¬æ–‡æ¡£æä¾›äº†ILD_Segmentationæ¨¡å—çš„å®Œæ•´æŠ€æœ¯å®ç°åˆ†æï¼Œæ¶µç›–ä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹è¯„ä¼°çš„å…¨éƒ¨æµç¨‹ã€‚**