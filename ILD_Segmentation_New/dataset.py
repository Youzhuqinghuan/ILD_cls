#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ILDåˆ†å‰²æ•°æ®é›†ç±»
å®žçŽ°æ”¯æŒè‚ºåˆ†å‰²é©±åŠ¨è¾¹ç•Œæ¡†ç”Ÿæˆå’ŒèƒŒæ™¯åˆ‡ç‰‡å¤„ç†çš„æ•°æ®é›†

ä¸»è¦åŠŸèƒ½ï¼š
1. åŠ è½½é¢„å¤„ç†åŽçš„å›¾åƒã€æ ‡ç­¾å’Œè‚ºåˆ†å‰²æ•°æ®
2. åŸºäºŽè‚ºåˆ†å‰²ç”Ÿæˆè¾¹ç•Œæ¡†ï¼Œè€Œéžä¾èµ–Ground Truth
3. æ”¯æŒèƒŒæ™¯åˆ‡ç‰‡ï¼ˆæ— ç—…å˜ï¼‰çš„è®­ç»ƒ
4. å®žçŽ°å¹³è¡¡é‡‡æ ·æœºåˆ¶
5. ä¸ŽSAM2æ¨¡åž‹å…¼å®¹çš„æ•°æ®æ ¼å¼
"""

import os
import json
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
import glob
import random
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
import logging
from sam2.utils.transforms import SAM2Transforms
import cv2

class ILDDataset(Dataset):
    """
    ILDåˆ†å‰²æ•°æ®é›†ç±»
    æ”¯æŒè‚ºåˆ†å‰²é©±åŠ¨çš„è¾¹ç•Œæ¡†ç”Ÿæˆå’ŒèƒŒæ™¯åˆ‡ç‰‡å¤„ç†
    """
    
    def __init__(self, 
                 data_root: str,
                 split: str = 'train',
                 bbox_shift: int = 20,
                 background_sample_ratio: float = 0.3,
                 confidence_threshold: float = 0.1,
                 target_resolution: int = 1024,
                 enable_background_training: bool = True,
                 lesion_type_mapping: Dict = None):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        
        Args:
            data_root: æ•°æ®æ ¹ç›®å½•ï¼ŒåŒ…å«train/val/testå­ç›®å½•
            split: æ•°æ®é›†åˆ’åˆ† ('train', 'val', 'test')
            bbox_shift: è¾¹ç•Œæ¡†éšæœºæ‰°åŠ¨èŒƒå›´
            background_sample_ratio: èƒŒæ™¯åˆ‡ç‰‡é‡‡æ ·æ¯”ä¾‹
            confidence_threshold: ç—…å˜æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
            target_resolution: ç›®æ ‡åˆ†è¾¨çŽ‡ï¼ˆSAM2è¾“å…¥ï¼‰
            enable_background_training: æ˜¯å¦å¯ç”¨èƒŒæ™¯åˆ‡ç‰‡è®­ç»ƒ
        """
        self.data_root = Path(data_root)
        self.split = split
        self.bbox_shift = bbox_shift
        self.background_sample_ratio = background_sample_ratio
        self.confidence_threshold = confidence_threshold
        self.enable_background_training = enable_background_training
        
        # ç—…å˜ç±»åž‹æ˜ å°„
        self.lesion_type_mapping = lesion_type_mapping or {
            0: "background",
            1: "GGO",
            2: "reticulation", 
            3: "consolidation",
            4: "honeycombing"
        }
        
        # è®¾ç½®è·¯å¾„
        self.split_dir = self.data_root / split
        self.img_dir = self.split_dir / 'imgs'
        self.gt_dir = self.split_dir / 'gts'
        self.lung_dir = self.split_dir / 'lungs'
        
        # éªŒè¯ç›®å½•å­˜åœ¨
        self._validate_directories()
        
        # SAM2å˜æ¢
        self._transform = SAM2Transforms(resolution=target_resolution, mask_threshold=0)
        
        # åŠ è½½æ–‡ä»¶åˆ—è¡¨å’Œå…ƒæ•°æ®
        self.file_list = self._load_file_list()
        self.metadata = self._load_metadata()
        
        # åˆ†æžæ•°æ®é›†
        self.dataset_stats = self._analyze_dataset()
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"åŠ è½½{split}æ•°æ®é›†: {len(self.file_list)}ä¸ªåˆ‡ç‰‡")
        self.logger.info(f"æ•°æ®é›†ç»Ÿè®¡: {self.dataset_stats}")
    
    def _validate_directories(self):
        """éªŒè¯å¿…è¦ç›®å½•å­˜åœ¨"""
        required_dirs = [self.img_dir, self.gt_dir, self.lung_dir]
        for dir_path in required_dirs:
            if not dir_path.exists():
                raise FileNotFoundError(f"å¿…è¦ç›®å½•ä¸å­˜åœ¨: {dir_path}")
    
    def _load_file_list(self) -> List[str]:
        """åŠ è½½æ–‡ä»¶åˆ—è¡¨"""
        # èŽ·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        img_files = sorted(glob.glob(str(self.img_dir / "*.npy")))
        
        # éªŒè¯å¯¹åº”çš„æ ‡ç­¾å’Œè‚ºåˆ†å‰²æ–‡ä»¶å­˜åœ¨
        valid_files = []
        for img_file in img_files:
            basename = os.path.basename(img_file)
            gt_file = self.gt_dir / basename
            lung_file = self.lung_dir / basename
            
            if gt_file.exists() and lung_file.exists():
                valid_files.append(basename.replace('.npy', ''))
            else:
                self.logger.warning(f"ç¼ºå°‘å¯¹åº”æ–‡ä»¶: {basename}")
        
        return valid_files
    
    def _load_metadata(self) -> Dict:
        """åŠ è½½åˆ‡ç‰‡å…ƒæ•°æ®"""
        metadata_file = self.data_root / 'slice_metadata.json'
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata_list = json.load(f)
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œä¾¿äºŽæŸ¥æ‰¾
            metadata_dict = {}
            for item in metadata_list:
                if isinstance(item, dict) and 'patient_id' in item and 'slice_name' in item:
                    slice_id = f"{item['patient_id']}_{item['slice_name']}"
                    metadata_dict[slice_id] = item
            
            return metadata_dict
        else:
            self.logger.warning("æœªæ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return {}
    
    def _analyze_dataset(self) -> Dict:
        """åˆ†æžæ•°æ®é›†ï¼Œç»Ÿè®¡èƒŒæ™¯å’Œç—…å˜åˆ‡ç‰‡"""
        background_count = 0
        lesion_count = 0
        lesion_type_count = {}
        
        for file_id in self.file_list:
            metadata = self.metadata.get(file_id, {})
            primary_lesion = metadata.get('primary_lesion', 0)
            
            # æ ¹æ®primary_lesionåˆ¤æ–­æ˜¯å¦ä¸ºèƒŒæ™¯
            if primary_lesion == 0:
                background_count += 1
            else:
                lesion_count += 1
            
            # ç»Ÿè®¡æ‰€æœ‰ç±»åž‹ï¼ˆåŒ…æ‹¬èƒŒæ™¯ï¼‰
            lesion_name = metadata.get('primary_lesion_name', 
                                     self.lesion_type_mapping.get(primary_lesion, f'æœªçŸ¥ç±»åž‹{primary_lesion}'))
            lesion_type_count[lesion_name] = lesion_type_count.get(lesion_name, 0) + 1
        
        return {
            'total': len(self.file_list),
            'background': background_count,
            'lesion': lesion_count,
            'lesion_types': lesion_type_count
        }
    
    def _get_lung_bbox(self, lung_mask: np.ndarray, padding: int = None) -> np.ndarray:
        """
        åŸºäºŽè‚ºåˆ†å‰²ç”Ÿæˆè¾¹ç•Œæ¡†
        
        Args:
            lung_mask: è‚ºåˆ†å‰²æŽ©ç  (256, 256)
            padding: è¾¹ç•Œæ¡†æ‰©å±•åƒç´ æ•°
            
        Returns:
            è¾¹ç•Œæ¡†åæ ‡ [x_min, y_min, x_max, y_max]ï¼Œå·²ç¼©æ”¾åˆ°1024åˆ†è¾¨çŽ‡
        """
        if padding is None:
            padding = self.bbox_shift
        
        h, w = lung_mask.shape
        
        # å¦‚æžœæ²¡æœ‰è‚ºåŒºåŸŸï¼Œè¿”å›žæ•´ä¸ªå›¾åƒçš„è¾¹ç•Œæ¡†
        if not np.any(lung_mask):
            return np.array([0, 0, w, h]) * 4  # ç¼©æ”¾åˆ°1024
        
        # æ‰¾åˆ°è‚ºåŒºåŸŸçš„è¾¹ç•Œ
        coords = np.where(lung_mask > 0)
        y_min, y_max = coords[0].min(), coords[0].max()
        x_min, x_max = coords[1].min(), coords[1].max()
        
        # æ·»åŠ éšæœºæ‰°åŠ¨ï¼ˆä»…åœ¨è®­ç»ƒæ—¶ï¼‰
        if self.split == 'train' and padding > 0:
            x_min = max(0, x_min - random.randint(0, padding))
            x_max = min(w, x_max + random.randint(0, padding))
            y_min = max(0, y_min - random.randint(0, padding))
            y_max = min(h, y_max + random.randint(0, padding))
        else:
            # éªŒè¯å’Œæµ‹è¯•æ—¶ä½¿ç”¨å›ºå®špadding
            x_min = max(0, x_min - padding // 2)
            x_max = min(w, x_max + padding // 2)
            y_min = max(0, y_min - padding // 2)
            y_max = min(h, y_max + padding // 2)
        
        # ç¼©æ”¾åˆ°1024åˆ†è¾¨çŽ‡
        bbox = np.array([x_min, y_min, x_max, y_max]) * 4
        
        return bbox
    
    def _process_labels(self, gt: np.ndarray, metadata: Dict) -> Tuple[np.ndarray, bool]:
        """
        å¤„ç†æ ‡ç­¾ï¼Œæ”¯æŒèƒŒæ™¯åˆ‡ç‰‡å’Œç—…å˜åˆ‡ç‰‡
        
        Args:
            gt: åŽŸå§‹æ ‡ç­¾ (256, 256)
            metadata: åˆ‡ç‰‡å…ƒæ•°æ®
            
        Returns:
            å¤„ç†åŽçš„äºŒå€¼æ ‡ç­¾ (256, 256) å’Œæ˜¯å¦ä¸ºèƒŒæ™¯åˆ‡ç‰‡çš„æ ‡å¿—
        """
        has_lesion = metadata.get('has_lesion', True)
        
        # å¦‚æžœæ˜¯èƒŒæ™¯åˆ‡ç‰‡
        if not has_lesion:
            return np.zeros_like(gt, dtype=np.uint8), True
        
        # å¦‚æžœæ˜¯ç—…å˜åˆ‡ç‰‡ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ªç—…å˜ç±»åž‹
        lesion_types = metadata.get('lesion_types', [])
        if not lesion_types:
            # å¦‚æžœå…ƒæ•°æ®ä¸­æ²¡æœ‰ç—…å˜ç±»åž‹ä¿¡æ¯ï¼Œä»Žæ ‡ç­¾ä¸­æå–
            unique_labels = np.unique(gt)
            lesion_types = unique_labels[unique_labels > 0].tolist()
        
        if lesion_types:
            # éšæœºé€‰æ‹©ä¸€ä¸ªç—…å˜ç±»åž‹è¿›è¡Œè®­ç»ƒ
            selected_lesion = random.choice(lesion_types)
            gt2d = (gt == selected_lesion).astype(np.uint8)
        else:
            # å¦‚æžœæ²¡æœ‰ç—…å˜ï¼Œè¿”å›žå…¨é›¶æ ‡ç­¾
            gt2d = np.zeros_like(gt, dtype=np.uint8)
            return gt2d, True
        
        return gt2d, False
    
    def __len__(self) -> int:
        return len(self.file_list)
    
    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, str, torch.Tensor]:
        """
        èŽ·å–å•ä¸ªæ•°æ®æ ·æœ¬
        
        Returns:
            img_1024: å›¾åƒå¼ é‡ [3, 1024, 1024]
            gt2d: æ ‡ç­¾å¼ é‡ [1, 256, 256]
            bbox: è¾¹ç•Œæ¡†å¼ é‡ [4]
            filename: æ–‡ä»¶å
            is_background: æ˜¯å¦ä¸ºèƒŒæ™¯åˆ‡ç‰‡çš„æ ‡å¿— [1]
        """
        file_id = self.file_list[index]
        
        # åŠ è½½æ•°æ®
        img = np.load(self.img_dir / f"{file_id}.npy")  # (256, 256, 3)
        gt = np.load(self.gt_dir / f"{file_id}.npy")    # (256, 256)
        lung_mask = np.load(self.lung_dir / f"{file_id}.npy")  # (256, 256)
        
        # èŽ·å–å…ƒæ•°æ®
        metadata = self.metadata.get(file_id, {})
        
        # å¤„ç†å›¾åƒï¼šè½¬æ¢ä¸ºSAM2æ ¼å¼
        img_1024 = self._transform(img.copy())  # [3, 1024, 1024]
        
        # å¤„ç†æ ‡ç­¾
        gt2d, is_background = self._process_labels(gt, metadata)
        
        # ç”ŸæˆåŸºäºŽè‚ºåˆ†å‰²çš„è¾¹ç•Œæ¡†
        bbox = self._get_lung_bbox(lung_mask)
        
        # è½¬æ¢ä¸ºå¼ é‡
        gt2d_tensor = torch.tensor(gt2d[None, :, :]).long()  # [1, 256, 256]
        bbox_tensor = torch.tensor(bbox).float()  # [4]
        is_background_tensor = torch.tensor([1.0 if is_background else 0.0]).float()  # [1]
        
        return img_1024, gt2d_tensor, bbox_tensor, file_id, is_background_tensor
    
    def create_balanced_sampler(self) -> Optional[WeightedRandomSampler]:
        """
        åˆ›å»ºå¹³è¡¡é‡‡æ ·å™¨ï¼ŒæŽ§åˆ¶èƒŒæ™¯å’Œç—…å˜åˆ‡ç‰‡çš„é‡‡æ ·æ¯”ä¾‹
        
        Returns:
            WeightedRandomSampleræˆ–Noneï¼ˆå¦‚æžœä¸éœ€è¦å¹³è¡¡é‡‡æ ·ï¼‰
        """
        if not self.enable_background_training or self.split != 'train':
            return None
        
        weights = []
        background_count = self.dataset_stats['background']
        lesion_count = self.dataset_stats['lesion']
        
        if background_count == 0 or lesion_count == 0:
            return None
        
        # è®¡ç®—æƒé‡ï¼Œä½¿èƒŒæ™¯åˆ‡ç‰‡å æŒ‡å®šæ¯”ä¾‹
        background_weight = self.background_sample_ratio / background_count
        lesion_weight = (1 - self.background_sample_ratio) / lesion_count
        
        for file_id in self.file_list:
            metadata = self.metadata.get(file_id, {})
            has_lesion = metadata.get('has_lesion', True)
            
            if has_lesion:
                weights.append(lesion_weight)
            else:
                weights.append(background_weight)
        
        return WeightedRandomSampler(weights, len(weights), replacement=True)
    
    def get_statistics(self) -> Dict:
        """èŽ·å–æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'dataset_stats': self.dataset_stats,
            'total_files': len(self.file_list),
            'split': self.split,
            'background_ratio': self.dataset_stats['background'] / self.dataset_stats['total'] if self.dataset_stats['total'] > 0 else 0
        }

def create_dataloader(data_root: str,
                     split: str = 'train',
                     batch_size: int = 8,
                     num_workers: int = 4,
                     bbox_shift: int = 20,
                     background_sample_ratio: float = 0.3,
                     enable_background_training: bool = True,
                     lesion_type_mapping: Dict = None,
                     **kwargs) -> DataLoader:
    """
    åˆ›å»ºæ•°æ®åŠ è½½å™¨
    
    Args:
        data_root: æ•°æ®æ ¹ç›®å½•
        split: æ•°æ®é›†åˆ’åˆ†
        batch_size: æ‰¹æ¬¡å¤§å°
        num_workers: å·¥ä½œè¿›ç¨‹æ•°
        bbox_shift: è¾¹ç•Œæ¡†æ‰°åŠ¨èŒƒå›´
        background_sample_ratio: èƒŒæ™¯åˆ‡ç‰‡é‡‡æ ·æ¯”ä¾‹
        enable_background_training: æ˜¯å¦å¯ç”¨èƒŒæ™¯åˆ‡ç‰‡è®­ç»ƒ
        **kwargs: å…¶ä»–å‚æ•°
        
    Returns:
        DataLoaderå®žä¾‹
    """
    dataset = ILDDataset(
        data_root=data_root,
        split=split,
        bbox_shift=bbox_shift,
        background_sample_ratio=background_sample_ratio,
        enable_background_training=enable_background_training,
        lesion_type_mapping=lesion_type_mapping,
        **kwargs
    )
    
    # åˆ›å»ºé‡‡æ ·å™¨
    sampler = dataset.create_balanced_sampler()
    shuffle = (split == 'train') and (sampler is None)
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        sampler=sampler,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=(split == 'train')
    )
    
    return dataloader

# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    import matplotlib.pyplot as plt
    import torchvision.transforms as transforms
    
    def test_dataset():
        """æµ‹è¯•æ•°æ®é›†åŠŸèƒ½"""
        print("å¼€å§‹æµ‹è¯•ILDæ•°æ®é›†...")
        
        # è®¾ç½®æ•°æ®è·¯å¾„ï¼ˆéœ€è¦æ ¹æ®å®žé™…æƒ…å†µä¿®æ”¹ï¼‰
        data_root = "data/preprocessed"
        
        try:
            # æµ‹è¯•è®­ç»ƒé›†
            print("\n=== æµ‹è¯•è®­ç»ƒé›† ===")
            train_dataset = ILDDataset(
                data_root=data_root,
                split='train',
                bbox_shift=20,
                background_sample_ratio=0.3,
                enable_background_training=True
            )
            
            print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
            print(f"æ•°æ®é›†ç»Ÿè®¡: {train_dataset.get_statistics()}")
            
            # æµ‹è¯•æ•°æ®åŠ è½½
            print("\n=== æµ‹è¯•æ•°æ®åŠ è½½ ===")
            for i in range(min(3, len(train_dataset))):
                img, gt, bbox, filename, is_background = train_dataset[i]
                print(f"æ ·æœ¬ {i}:")
                print(f"  æ–‡ä»¶å: {filename}")
                print(f"  å›¾åƒå½¢çŠ¶: {img.shape}")
                print(f"  æ ‡ç­¾å½¢çŠ¶: {gt.shape}")
                print(f"  è¾¹ç•Œæ¡†: {bbox}")
                print(f"  æ˜¯å¦èƒŒæ™¯: {is_background.item() > 0.5}")
                
                # éªŒè¯æ•°æ®èŒƒå›´
                assert img.shape == (3, 1024, 1024), f"å›¾åƒå½¢çŠ¶é”™è¯¯: {img.shape}"
                assert gt.shape == (1, 256, 256), f"æ ‡ç­¾å½¢çŠ¶é”™è¯¯: {gt.shape}"
                assert bbox.shape == (4,), f"è¾¹ç•Œæ¡†å½¢çŠ¶é”™è¯¯: {bbox.shape}"
                assert is_background.shape == (1,), f"èƒŒæ™¯æ ‡å¿—å½¢çŠ¶é”™è¯¯: {is_background.shape}"
                assert torch.all(gt >= 0) and torch.all(gt <= 1), f"æ ‡ç­¾å€¼èŒƒå›´é”™è¯¯: {gt.min()}-{gt.max()}"
                
                print("  âœ“ æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡")
            
            # æµ‹è¯•DataLoader
            print("\n=== æµ‹è¯•DataLoader ===")
            train_loader = create_dataloader(
                data_root=data_root,
                split='train',
                batch_size=4,
                num_workers=0,  # æµ‹è¯•æ—¶ä½¿ç”¨0é¿å…å¤šè¿›ç¨‹é—®é¢˜
                background_sample_ratio=0.3
            )
            
            batch_count = 0
            for batch_imgs, batch_gts, batch_bboxes, batch_names, batch_is_background in train_loader:
                print(f"æ‰¹æ¬¡ {batch_count}:")
                print(f"  æ‰¹æ¬¡å¤§å°: {len(batch_names)}")
                print(f"  å›¾åƒæ‰¹æ¬¡å½¢çŠ¶: {batch_imgs.shape}")
                print(f"  æ ‡ç­¾æ‰¹æ¬¡å½¢çŠ¶: {batch_gts.shape}")
                print(f"  è¾¹ç•Œæ¡†æ‰¹æ¬¡å½¢çŠ¶: {batch_bboxes.shape}")
                print(f"  èƒŒæ™¯æ ‡å¿—å½¢çŠ¶: {batch_is_background.shape}")
                
                # ç»Ÿè®¡èƒŒæ™¯åˆ‡ç‰‡æ¯”ä¾‹
                background_count = torch.sum(batch_is_background > 0.5).item()
                print(f"  èƒŒæ™¯åˆ‡ç‰‡æ•°é‡: {background_count}/{len(batch_names)}")
                
                batch_count += 1
                if batch_count >= 3:  # åªæµ‹è¯•å‰3ä¸ªæ‰¹æ¬¡
                    break
            
            print("\n=== æµ‹è¯•éªŒè¯é›† ===")
            val_dataset = ILDDataset(
                data_root=data_root,
                split='val',
                enable_background_training=False  # éªŒè¯æ—¶ä¸å¯ç”¨èƒŒæ™¯è®­ç»ƒ
            )
            print(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}")
            
            # æµ‹è¯•è¾¹ç•Œæ¡†ç”Ÿæˆ
            print("\n=== æµ‹è¯•è¾¹ç•Œæ¡†ç”Ÿæˆ ===")
            sample_img, sample_gt, sample_bbox, sample_name, sample_is_background = val_dataset[0]
            print(f"æ ·æœ¬è¾¹ç•Œæ¡†: {sample_bbox}")
            print(f"è¾¹ç•Œæ¡†èŒƒå›´æ£€æŸ¥: x=[{sample_bbox[0]:.1f}, {sample_bbox[2]:.1f}], y=[{sample_bbox[1]:.1f}, {sample_bbox[3]:.1f}]")
            print(f"æ˜¯å¦èƒŒæ™¯åˆ‡ç‰‡: {sample_is_background.item() > 0.5}")
            
            # éªŒè¯è¾¹ç•Œæ¡†åˆç†æ€§
            assert sample_bbox[0] >= 0 and sample_bbox[2] <= 1024, "Xåæ ‡è¶…å‡ºèŒƒå›´"
            assert sample_bbox[1] >= 0 and sample_bbox[3] <= 1024, "Yåæ ‡è¶…å‡ºèŒƒå›´"
            assert sample_bbox[0] < sample_bbox[2], "Xåæ ‡é¡ºåºé”™è¯¯"
            assert sample_bbox[1] < sample_bbox[3], "Yåæ ‡é¡ºåºé”™è¯¯"
            print("  âœ“ è¾¹ç•Œæ¡†éªŒè¯é€šè¿‡")
            
            print("\nðŸŽ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            
        except FileNotFoundError as e:
            print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°é”™è¯¯: {e}")
            print("è¯·ç¡®ä¿æ•°æ®é¢„å¤„ç†å·²å®Œæˆï¼Œå¹¶ä¸”æ•°æ®è·¯å¾„æ­£ç¡®")
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # è¿è¡Œæµ‹è¯•
    test_dataset()